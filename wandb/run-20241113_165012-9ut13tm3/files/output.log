/scratch/zhoujunting/anaconda3/envs/MAGA/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "/scratch/zhoujunting/zjt/task3.py", line 101, in <module>
    model.add_adapter(dataset,adapter_config)
  File "/scratch/zhoujunting/anaconda3/envs/MAGA/lib/python3.10/site-packages/transformers/integrations/peft.py", line 265, in add_adapter
    raise TypeError(f"adapter_config should be an instance of PeftConfig. Got {type(adapter_config)} instead.")
TypeError: adapter_config should be an instance of PeftConfig. Got <class 'str'> instead.
